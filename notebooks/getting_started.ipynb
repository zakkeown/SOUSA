{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with SOUSA Dataset\n",
    "\n",
    "This notebook demonstrates how to load, explore, and use the SOUSA (Synthetic Open Unified Snare Assessment) dataset for machine learning tasks.\n",
    "\n",
    "**Contents:**\n",
    "1. Loading the Dataset\n",
    "2. Exploring the Data Structure\n",
    "3. Playing Audio Samples\n",
    "4. Visualizing Score Distributions\n",
    "5. Filtering for ML Training\n",
    "6. Basic Model Training Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Dataset\n",
    "\n",
    "SOUSA can be loaded from HuggingFace Hub or from a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Load from HuggingFace Hub\n",
    "from datasets import load_dataset\n",
    "\n",
    "# This downloads the dataset (first time only)\n",
    "dataset = load_dataset(\"zkeown/sousa\")\n",
    "\n",
    "print(f\"Dataset loaded with splits: {list(dataset.keys())}\")\n",
    "print(f\"Train samples: {len(dataset['train']):,}\")\n",
    "print(f\"Validation samples: {len(dataset['validation']):,}\")\n",
    "print(f\"Test samples: {len(dataset['test']):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Load from local directory (if you generated the dataset yourself)\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Adjust this path to your local dataset\n",
    "LOCAL_DATASET_DIR = Path(\"../output/dataset\")\n",
    "\n",
    "if LOCAL_DATASET_DIR.exists():\n",
    "    samples_df = pd.read_parquet(LOCAL_DATASET_DIR / \"labels\" / \"samples.parquet\")\n",
    "    exercises_df = pd.read_parquet(LOCAL_DATASET_DIR / \"labels\" / \"exercises.parquet\")\n",
    "    print(f\"Loaded {len(samples_df):,} samples from local directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Data Structure\n",
    "\n",
    "Each sample contains:\n",
    "- **Audio**: FLAC file of the performance\n",
    "- **Metadata**: rudiment, skill tier, tempo, etc.\n",
    "- **Scores**: Performance quality scores (0-100 scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a single sample\n",
    "sample = dataset['train'][0]\n",
    "\n",
    "print(\"Sample fields:\")\n",
    "for key, value in sample.items():\n",
    "    if key == 'audio':\n",
    "        print(f\"  {key}: array shape {value['array'].shape}, sr={value['sampling_rate']}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View skill tier distribution\n",
    "import collections\n",
    "\n",
    "tier_counts = collections.Counter(dataset['train']['skill_tier'])\n",
    "print(\"Skill tier distribution:\")\n",
    "for tier in ['beginner', 'intermediate', 'advanced', 'professional']:\n",
    "    count = tier_counts.get(tier, 0)\n",
    "    pct = 100 * count / len(dataset['train'])\n",
    "    print(f\"  {tier:15s}: {count:6,} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View rudiment distribution (top 10)\n",
    "rudiment_counts = collections.Counter(dataset['train']['rudiment_slug'])\n",
    "print(\"Top 10 rudiments:\")\n",
    "for rudiment, count in rudiment_counts.most_common(10):\n",
    "    print(f\"  {rudiment:30s}: {count:5,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Playing Audio Samples\n",
    "\n",
    "You can listen to audio samples directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "def play_sample(sample, label=None):\n",
    "    \"\"\"Play audio from a dataset sample.\"\"\"\n",
    "    audio_array = sample['audio']['array']\n",
    "    sample_rate = sample['audio']['sampling_rate']\n",
    "    \n",
    "    if label:\n",
    "        print(label)\n",
    "    print(f\"  Rudiment: {sample['rudiment_slug']}\")\n",
    "    print(f\"  Skill Tier: {sample['skill_tier']}\")\n",
    "    print(f\"  Tempo: {sample['tempo_bpm']} BPM\")\n",
    "    print(f\"  Overall Score: {sample['overall_score']:.1f}\")\n",
    "    \n",
    "    display(Audio(audio_array, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to a beginner vs professional comparison\n",
    "train_data = dataset['train']\n",
    "\n",
    "# Find a paradiddle from each tier\n",
    "rudiment = 'single_paradiddle'\n",
    "\n",
    "beginner_sample = None\n",
    "professional_sample = None\n",
    "\n",
    "for sample in train_data:\n",
    "    if sample['rudiment_slug'] == rudiment:\n",
    "        if sample['skill_tier'] == 'beginner' and beginner_sample is None:\n",
    "            beginner_sample = sample\n",
    "        elif sample['skill_tier'] == 'professional' and professional_sample is None:\n",
    "            professional_sample = sample\n",
    "    if beginner_sample and professional_sample:\n",
    "        break\n",
    "\n",
    "if beginner_sample:\n",
    "    play_sample(beginner_sample, \"BEGINNER:\")\n",
    "    print()\n",
    "\n",
    "if professional_sample:\n",
    "    play_sample(professional_sample, \"PROFESSIONAL:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Score Distributions\n",
    "\n",
    "Explore how scores differ across skill tiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "train_df = dataset['train'].to_pandas()\n",
    "\n",
    "# Score columns\n",
    "score_cols = ['overall_score', 'timing_accuracy', 'timing_consistency', \n",
    "              'velocity_control', 'hand_balance']\n",
    "\n",
    "# Filter to score columns that exist\n",
    "score_cols = [c for c in score_cols if c in train_df.columns]\n",
    "\n",
    "print(f\"Available score columns: {score_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot score distributions by skill tier\n",
    "fig, axes = plt.subplots(1, len(score_cols), figsize=(4*len(score_cols), 4))\n",
    "if len(score_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "tier_order = ['beginner', 'intermediate', 'advanced', 'professional']\n",
    "colors = ['#e74c3c', '#f39c12', '#2ecc71', '#3498db']\n",
    "\n",
    "for ax, col in zip(axes, score_cols):\n",
    "    for tier, color in zip(tier_order, colors):\n",
    "        tier_data = train_df[train_df['skill_tier'] == tier][col]\n",
    "        ax.hist(tier_data, bins=30, alpha=0.6, label=tier.capitalize(), color=color)\n",
    "    ax.set_xlabel(col.replace('_', ' ').title())\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Score Distributions by Skill Tier', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by tier\n",
    "print(\"Mean Overall Score by Skill Tier:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for tier in tier_order:\n",
    "    tier_scores = train_df[train_df['skill_tier'] == tier]['overall_score']\n",
    "    print(f\"{tier.capitalize():15s}: {tier_scores.mean():5.1f} +/- {tier_scores.std():4.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap of scores\n",
    "import seaborn as sns\n",
    "\n",
    "score_df = train_df[score_cols]\n",
    "corr_matrix = score_df.corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Score Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filtering for ML Training\n",
    "\n",
    "Filter the dataset based on your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by skill tier\n",
    "advanced_professional = dataset['train'].filter(\n",
    "    lambda x: x['skill_tier'] in ['advanced', 'professional']\n",
    ")\n",
    "print(f\"Advanced + Professional samples: {len(advanced_professional):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by rudiment\n",
    "paradiddles = dataset['train'].filter(\n",
    "    lambda x: 'paradiddle' in x['rudiment_slug']\n",
    ")\n",
    "print(f\"Paradiddle samples: {len(paradiddles):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by score range (e.g., samples with score > 80)\n",
    "high_quality = dataset['train'].filter(\n",
    "    lambda x: x['overall_score'] > 80\n",
    ")\n",
    "print(f\"High quality (score > 80) samples: {len(high_quality):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary classification dataset (beginner vs professional)\n",
    "def add_binary_label(example):\n",
    "    if example['skill_tier'] == 'professional':\n",
    "        example['is_professional'] = 1\n",
    "    else:\n",
    "        example['is_professional'] = 0\n",
    "    return example\n",
    "\n",
    "binary_dataset = dataset['train'].filter(\n",
    "    lambda x: x['skill_tier'] in ['beginner', 'professional']\n",
    ").map(add_binary_label)\n",
    "\n",
    "print(f\"Binary classification samples: {len(binary_dataset):,}\")\n",
    "print(f\"  Beginner: {sum(1 for x in binary_dataset if x['is_professional'] == 0):,}\")\n",
    "print(f\"  Professional: {sum(1 for x in binary_dataset if x['is_professional'] == 1):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Basic Model Training Example\n",
    "\n",
    "A minimal example showing how to train a classifier on SOUSA.\n",
    "\n",
    "**Note:** This is a simplified example for demonstration. For production use, consider:\n",
    "- Using a proper audio feature extractor (e.g., mel spectrograms)\n",
    "- Larger models (e.g., Audio Spectrogram Transformer)\n",
    "- Proper hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this cell if you don't have transformers/torch installed\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import DataLoader\n",
    "    TORCH_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print(\"PyTorch not available. Skip the model training example.\")\n",
    "    print(\"Install with: pip install torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    # Simple feature extraction: RMS energy in chunks\n",
    "    def extract_features(audio_array, n_chunks=16):\n",
    "        \"\"\"Extract simple RMS features from audio.\"\"\"\n",
    "        chunk_size = len(audio_array) // n_chunks\n",
    "        features = []\n",
    "        for i in range(n_chunks):\n",
    "            chunk = audio_array[i*chunk_size:(i+1)*chunk_size]\n",
    "            rms = np.sqrt(np.mean(chunk**2))\n",
    "            features.append(rms)\n",
    "        return np.array(features, dtype=np.float32)\n",
    "    \n",
    "    # Prepare data\n",
    "    def prepare_batch(examples):\n",
    "        features = []\n",
    "        labels = []\n",
    "        for ex in examples:\n",
    "            feat = extract_features(ex['audio']['array'])\n",
    "            features.append(feat)\n",
    "            # Skill tier to numeric (0-3)\n",
    "            tier_map = {'beginner': 0, 'intermediate': 1, 'advanced': 2, 'professional': 3}\n",
    "            labels.append(tier_map[ex['skill_tier']])\n",
    "        return torch.tensor(np.stack(features)), torch.tensor(labels)\n",
    "    \n",
    "    print(\"Feature extraction function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    # Simple classifier\n",
    "    class SimpleClassifier(nn.Module):\n",
    "        def __init__(self, input_dim=16, hidden_dim=32, num_classes=4):\n",
    "            super().__init__()\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(hidden_dim, num_classes),\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "    \n",
    "    model = SimpleClassifier()\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    # Quick training loop on a small subset\n",
    "    # In practice, use the full dataset with proper batching\n",
    "    \n",
    "    # Get small training and validation sets\n",
    "    train_subset = dataset['train'].shuffle(seed=42).select(range(500))\n",
    "    val_subset = dataset['validation'].shuffle(seed=42).select(range(100))\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train, y_train = prepare_batch(train_subset)\n",
    "    X_val, y_val = prepare_batch(val_subset)\n",
    "    \n",
    "    # Training\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(\"Training simple classifier (500 samples, 50 epochs)...\")\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(X_val)\n",
    "                val_preds = val_outputs.argmax(dim=1)\n",
    "                val_acc = (val_preds == y_val).float().mean().item()\n",
    "            print(f\"Epoch {epoch+1:3d}: loss={loss.item():.4f}, val_acc={val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_preds = val_outputs.argmax(dim=1)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    \n",
    "    tier_names = ['beginner', 'intermediate', 'advanced', 'professional']\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val.numpy(), val_preds.numpy(), target_names=tier_names))\n",
    "    \n",
    "    print(\"\\nNote: This is a simplified example with basic features.\")\n",
    "    print(\"For better results, use mel spectrograms or pre-trained audio models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've explored the dataset, here are some ideas for what to do next:\n",
    "\n",
    "1. **Score Regression**: Train a model to predict overall_score from audio\n",
    "2. **Rudiment Classification**: Classify which of the 40 rudiments is being played\n",
    "3. **Skill Assessment**: Build a system that provides feedback on drumming quality\n",
    "4. **Transfer Learning**: Fine-tune a pre-trained audio model (e.g., Wav2Vec2, HuBERT)\n",
    "\n",
    "For more information, see the [SOUSA documentation](https://github.com/zkeown/rudimentary)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
